# Задачи курса "Основы информационного поиска"

## Выполнили: [Торопов Дмитрий Александрович](https://github.com/DeM0NChiCk) и [Чивилев Никита Сергеевич](https://github.com/nVoxel)

### Задание №1

#### Требования

- создать краулер
 
#### Результат

- links.zip: архив с выкаченными страницами в формате html
- index.txt: текстовый файл в котором хранятся номера файлов и ссылки на страницы

#### Инструменты

- Python 3.12 
- beautifulsoup4 4.13.3  

Beautiful Soup — это библиотека, которая упрощает сбор информации с веб-страниц. Она располагается поверх HTML- или XML-парсера, предоставляя Pythonic-идиомы для итерации, поиска и изменения дерева парсинга.

#### Ссылки для краулера (последняя дата обращения 18.03.2025)

Научно-популярные статьи рубрики: Исследования
- https://www.trv-science.ru/category/news/
- https://www.trv-science.ru/category/news/path/2

#### Запуск

- Установите необходимые пакеты: `pip install beautifulsoup4`
- `python crawler.py`

### Задание №2

#### Требования

- разбить текст на отдельные слова (токены) на кириллице
- отфильтровать токены
- лемматизировать оставшиеся токены

#### Входные данные

- папка links, в которой лежат HTML-файлы вида unloading_N.html, где N — целое число
- каждый HTML-файл должен содержать блок \<div id="main"> и внутри него хотя бы один дочерний \<div>, откуда будет браться текст

#### Результат
Для каждого unloading_N.html создаются два файла:
- tokens_unloading_N.txt: cписок токенов (по одному в каждой строке)
- lemmas_unloading_N.txt: cписок лемм и соответствующих им форм в виде

#### Инструменты
- Python 3.10 (pymorphy не работает на Python 3.12)
- beautifulsoup4 4.13.3 - для парсинга HTML-страниц и удобного извлечения нужных элементов из DOM
- nltk 3.9.1 - для токенизации и работы со стоп-словами
- pymorphy2 0.9.1 - морфологический анализатор русского языка, позволяет определять леммы

#### Запуск
- Установите необходимые пакеты: `pip install beautifulsoup4 nltk pymorphy2`
- Скачайте необходимые данные NLTK (стоп-слова, punkt), если ещё не скачивали:
```python
import nltk
nltk.download('stopwords')
nltk.download('punkt')
```
- `python tokenizer.py`

### Задание №3

#### Требования

- создать инвертированный список терминов (индекс)
- реализовать булев поиск по построенному индексу
- Замечание:
  - в рамках выполнения задания должны быть реализованы операторы AND, OR, NOT
  - возможность вводить сложный запрос ( например, (Клеопатра  AND Цезарь) OR (Антоний AND Цицерон) OR Помпей
  - реализована возможность водить  запрос  строку запроса (то есть запрос не "хардкодим")

#### Входные данные

- папка links, в которой лежат HTML-файлы вида unloading_N.html, где N — целое число
- папка lemmas, в которой лежат файлы lemmas_unloading_N.txt: cписок лемм и соответствующих им форм в виде

#### Результат

Создаётся файл c индексами (инвертированный список терминов)
- inverted_index.txt: файл, в котором для каждой леммы указывается список документов (unloading_N), в которых она встречается в каталоге links.
    - lemma: unloading_1 unloading_2 ... unloading_N

boolean_search.py: код булева запроса (поддерживается AND, OR, NOT, скобки). Взаимодействие с пользователем через консоль ввода  

Примеры ввода:
> (взрыв OR вспышка) AND (галактика OR вселенная)

> вода AND NOT газ

> (галактика AND газ) AND NOT вспышка

#### Инструменты
- Python 3.10 (pymorphy не работает на Python 3.12)
- nltk 3.9.1 - для токенизации и работы со стоп-словами
- pymorphy2 0.9.1 - морфологический анализатор русского языка, позволяет определять леммы

#### Запуск 
- Установите необходимые пакеты: `pip install nltk pymorphy2`
- Скачайте необходимые данные NLTK (стоп-слова, punkt), если ещё не скачивали:
```python
import nltk
nltk.download('stopwords')
nltk.download('punkt')
```
- `python boolean_search.py`